Good afternoon and welcome to NVIDIA's third quarter earnings call for fiscal year 2025. The speakers are Jensen Wong, president and CEO, and Collette Cress, executive VP and CFO. The content of the call is property of NVIDIA and cannot be reproduced or transcribed without permission. Forward-looking statements may differ from actual results due to various risks and uncertainties. Reports on form 8K with SEC dis The company reported a record quarter with strong sequential and year-on-year growth driven by the adoption of NVIDIA accelerated computing and AI. Revenue reached $35.1 billion, up 94% year-on-year. Data center sales increased to $30.8 billion due to exceptional demand for NVIDIA Hopper products. Cloud service providers' revenue doubled year-on-year as they deployed NVIDIA H200 infrastructure and high NVIDIA is a leading inference platform with continuous performance improvements, which has resulted in increased efficiency for developers. The upcoming release of NVIDIA's NEM will further enhance the platform's capabilities. Blackwell, a full-stack AI data center system, is now in production and being used by major partners to scale their data centers. Demand for Blackwell is high, and companies like Oracle and Microsoft are integrating it into their cloud computing services. Blackwell, an architecture from NVIDIA, has achieved impressive results in the latest ML Perf training round, showing a significant leap in performance over high-end systems and reducing compute costs. This advancement will enable new reasoning applications like Open AI's 01 model to perform better. The success of startups using AI services is growing rapidly, with many companies already delivering successful AI services. Enterprise AI and Industrial AI are the next waves for AI development, with industry leaders working on building Over 900 companies use NVIDIA's technology, with a significant increase expected in AI Enterprise monetization. The company expects its annual revenue to double this year and is seeing strong growth in software, service, and support revenues. Industrial AI and robotics are accelerating due to breakthroughs in physical AI models like NVIDIA NEMO for enterprise agents and Omiverse for developers. Major industrial manufacturers such as Foxconn are adopting these technologies to improve efficiency. Infosys, TLC, Wipro are adopting NVIDIA AI Enterprise to train developers and consultants in AI technology. In Japan, SoftBank is building an AI supercomputer using NVIDIA DGX Blackwell and Kartsman Finnebaum. The telecommunications network will be transformed into a distributed AI network with the help of NVIDIA's AI Arial and AI RAN platform. Networking revenue increased by 20% year The strong back to school sales have driven demand for GeForce RTX GPUs and devices as consumers choose them for gaming, creative, and AI applications. Channel inventory remains healthy in preparation for the holiday season. New GeForce RTX AI PCs with up to 321 AI tops from ASUS and MSI are being shipped with Microsoft's co-pilot plus capabilities anticipated in Q4. These machines utilize RTX ray tracing and AI technologies to enhance gaming, photo and The company returned $11.2 billion to shareholders during Q3 through share repurchases and cash dividends. For Q4, total revenue is expected to be around $37.5 billion with a 2% variation due to increased demand for hopper architecture and the initial ramp of Blackwell products. The company expects to exceed its previous Blackwell revenue estimate as supply visibility improves. Gaming revenue is predicted to decline sequentially in Q4 due to supply constraints. G We will be attending various conferences and events, including a keynote at CES on January 6th and a Q&A session for financial analysts on January 7th. Our earnings call is scheduled for February 26th, 2025. During the call, we can discuss the debate around large language model scaling and how it affects our customers. We've discovered two new ways to scale: post-training scaling using reinforcement learning AI feedback and synthetic The text discusses the improvements in AI models and their scaling capabilities. It mentions that demand for infrastructure is high due to these advancements. Inference time scaling has also increased, leading to more companies adopting AI technology. Enterprise adoption of agentic AI is growing as well. There are reports about heating issues related to a mass change earlier this year, but the text does not provide further details on this matter. The company has been working hard on increasing the production of Blackwell and expects to deliver more this quarter than previously estimated. Demand for Blackwell is strong due to the beginning of a generative AI revolution. Engineering work is being done across the world with various companies standing up systems that use Blackwell, including Dell, CoreWeave, Oracle, Microsoft, and Google. The supply chain team is working closely with partners to increase production through next year. The text discusses how a company has built an AI supercomputer and integrated it into custom data centers worldwide. They have done several generations of integration and are very good at it but still require significant engineering work. There is a supply chain with seven different chips for the blackwell systems, which can be air-cooled or liquid-cooled, using various NVLink types or x86 or grace processors. The company has great partners in the supply chain, including TS The company follows an annual roadmap and plans to continue executing on this plan to increase platform performance. This approach reduces costs for training, inferencing, and AI, making it more accessible. As data centers become larger, the focus is on maximizing power efficiency per watt, which leads to higher revenues for customers. The company intends to stay on track with its annual roadmap and will continue to improve performance while reducing costs. The speaker discusses Blackwell ramping up gross margins to the low 70s in April as they focus on providing the best experience for customers. They expect these margins to increase quickly, reaching mid-70s soon after. Hopper demand will continue through next year and more Blackwells will be shipped each quarter. The speaker highlights two significant shifts in computing: moving from coding that runs on CPUs to machine learning running on GPUs, which is now widespread; and In this text, the speaker discusses how data centers are becoming AI factories that generate artificial intelligence like electricity is generated. They mention that these systems will be running 24/7 and that this trend is just beginning. The speaker also talks about a possible recovery of NVIDIA's gross margins to mid-70s in the back half of calendar year 25, as well as the historical pattern of hardware deployment cycles involving periods of digestion. They are asked how It is possible that we could reach the mid-70s in the second half of next year, but it depends on how well we modernize data centers. Over the next few years, the world's data centers should be upgraded to accommodate machine learning and generative AI as IT continues to grow at a rapid pace. Additionally, new market segments will emerge with companies like OpenAI offering brand-new services that generate intelligence in various fields such as digital art, law, marketing, and AI native companies are growing rapidly due to the platform shift they represent. These companies aim to modernize IT and computing, while also creating new industries for artificial intelligence production. The speaker is then asked about their gross margins and whether Blackwell's revenue will increase in the next quarter. They mention that Hopper has been strong as well but do not provide specific details on why Blackwell may be down sequentially during this period. The speaker discusses improvements to yields, products, and sales throughout the year with a goal of reaching mid-70s by the end. They mention substantial growth in H-200 orders and expect Hopper clusters to continue growing between Q3 and Q4. Regarding inference markets, they hope for widespread use of AI within companies for various departments as a sign of success. The speaker believes that companies should constantly use AI for various tasks like reading PDFs or using Excel, generating tokens as they do so. They mention a new era of AI called physical AI which understands the physical world and can predict outcomes. This has led to many startups in AI native companies and robotics companies. Omniverse was created to enable these AIs to learn from synthetic data generation and reinforcement learning physics feedback instead of human feedback. The speaker is excited about this growth and development Inference is difficult due to high accuracy and low latency requirements while maintaining a low cost. Applications require long context lengths, which increases the model size. The innovation rate in this field makes NVIDIA's architecture unique because of its ecosystem that allows faster development on top of CUDA. This enables broad deployment worldwide across data centers and edge devices. In the last quarter, networking business saw a 15% decrease sequentially but strong demand was observed with multiple cloud design wins for The networking business has experienced tremendous growth year over year since acquiring Melanox. Focus has been on building work in data centers with a critical part being networking. This quarter saw a slight dip but is expected to grow again soon as more systems are incorporated into large systems. Sovereign AI demand remains strong, and the pipeline for this is still intact. Supply constraints may be due to shifting supply towards data center needs. The speaker discusses growth opportunities in regional clouds and AI factories, particularly in Europe and Asia Pacific regions. They also mention challenges with gaming supply for this quarter but expect improvements in the new year. Regarding a change in administration in the U.S., they acknowledge it's too early to predict any impacts on tariffs or China business. The speaker discusses how their company works with suppliers worldwide, emphasizing compliance with regulations while supporting customers and competing in the marketplace. They mention pre-training, reinforcement learning, and inference as key components of an AI ecosystem and highlight that most compute resources currently go into pre-training foundation models. As new technologies emerge, they aim to reduce inference costs for everyone by balancing pre-training and post-training efforts. The speaker discusses the rapid growth in foundation models for AI, particularly in video processing. This requires more compute power and increased efficiency to keep costs down while revenues rise. Two main trends are driving this growth: 1) A platform shift from coding on CPUs to machine learning on GPUs; and 2) The age of AI with the emergence of generative AI as a new industry, leading to a multi-trillion dollar market. Demand for NVIDIA's Artificial intelligence (AI) is transforming every industry, company, and country. Enterprises are adopting AI technology to revolutionize workflows, making employees more efficient in their jobs. Investments in industrial robotics are increasing due to advancements in physical AI. This has led to a demand for new training infrastructure as researchers train world foundation models on large amounts of data. The age of robotics is approaching and countries worldwide recognize the importance of developing national AI infrastructure. NVIDIA