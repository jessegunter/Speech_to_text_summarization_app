This is a transcript from NVIDIA's third quarter earnings conference call in fiscal 2025. The speaker introduces the participants and reminds listeners that the content cannot be reproduced or transcribed without permission. They also mention forward-looking statements, which are subject to risks and uncertainties. Non-GAAP financial measures will be discussed during this call. In Q3, NVIDIA achieved record revenues of $35.1 billion, a 94% increase year-on-year and above the outlook of $32.5 billion. All market platforms posted strong sequential and yearly growth driven by adoption of NVIDIA's accelerated computing and AI technology. Data center revenue reached $30.8 billion, up 17% sequentially and 112% year-on-year. The H200 product saw significant sales increases with improved performance and TCO. Cloud service providers doubled their revenues from the previous year. Consumer internet revenue more than doubled as companies scaled NVIDIA's hopper infrastructure NVIDIA is a leading player in the inference platform market with an extensive install base and software ecosystem that encourages developers to optimize for their products. Rapid advancements in NVIDIA's algorithms have led to significant improvements in performance and cost savings. The upcoming release of NVIDIA NEM will further enhance hopper inference performance by 2.4x. Blackwell, a full stack AI data center system with customizable configurations, is now in production after a successful mouse change. Demand for the product has been high, and NVIDIA is working to scale supply to meet customer needs. Major partners are integrating Blackwell systems into their diverse data center configurations. Oracle announced ZetaScale AI cloud computing clusters Blackwell has made its debut on the ML Perf training results and demonstrated an impressive leap in performance over high-end systems. The technology requires fewer GPUs for benchmarking compared to other models, reducing costs significantly. NVIDIA's new architecture enables faster inference performance, opening up opportunities for AI native companies to deliver services with great success. Enterprise AI is also gaining momentum, with industry leaders using NVIDIA AI technology to build co-pilots and agents. Consulting firms like Accenture are leveraging this technology both internally and externally, helping facilitate the global adoption of Genic AI applications. Over 900 companies use NVIDIA's NEM software and its adoption is accelerating AI monetization. The company expects full-year revenue to double from last year, with a pipeline that continues to grow. Software, service, and support revenues are annualizing at $1.5 billion and are expected to exceed $2 billion this year. Industrial AI and robotics are being driven by breakthroughs in physical AI models. NVIDIA's Omiverse is used by major industrial manufacturers like Foxconn for automation and efficiency improvements. In China, data center revenue grew sequentially due to export compliant shipments, but remains below pre-export control levels. The company will continue to comply with export controls Infosys, TLC, Wipro are adopting NVIDIA AI Enterprise to train developers and consultants in building and running AI agents. In Japan, SoftBank is using the technology to build an AI supercomputer with DGX Blackwell and Kartsman Finnebaum. They're also partnering with NVIDIA for a distributed AI network. Fujitsu, NEC, and NTT are adopting this in Japan while major consulting companies like EY, Strategy and Consulting will help bring the technology to Japanese industries. Networking revenue increased 20% year on year, including InfiniBand and Ethernet switches, smartNICs, and Blue Nvidia's RTX GPUs have been in high demand during back-to-school sales as consumers choose them for gaming, creative, and AI applications. Channel inventory remains healthy ahead of the holiday season. The company has begun shipping new GeForce RTX AI PCs with up to 321 AI tops from ASUS and MSI, which are expected to have Microsoft's co-pilot plus capabilities in Q4. These machines utilize RTX ray tracing and AI technologies for gaming, photo and video editing, image generation, and coding. Nvidia is celebrating the 25th anniversary of its first GPU, the GeForce 256, which has been instrumental in driving significant technological advance The company returned $11.2 billion to shareholders through repurchases and dividends in Q3. For Q4, total revenue is expected to be around $37.5 billion with a 2% variance due to continued demand for hopper architecture and initial ramp of Blackwell products. Blackwell is an AI infrastructure that includes NVIDIA-built chips and networking options. The company expects margins to moderate as it ramps up production, eventually reaching the mid-70s. Gap and non-gap operating expenses are expected to be around $4.8 billion and $3.4 billion respectively. Other income and expenses are estimated at approximately $400 million, excluding gains from non- We will be attending a conference on December 3rd and CES event on January 6th where Genson will deliver a keynote. A Q&A session for financial analysts is scheduled for January 7th. An earnings call about the fourth quarter of fiscal 2025 is set for February 26th, 2025. We are discussing large language model scaling and how it affects our customers. Foundation model pre-training scaling continues to scale, but we have discovered two other ways: post-training scaling with reinforcement learning AI feedback and synthetic data, as well as inference time scaling through Strawberry, ChatGPT01, OpenAI01. The text discusses how AI models are improving in quality as they think longer and consider various techniques. It mentions three ways of scaling that have led to a high demand for infrastructure. Inference time is also scaling up, resulting in increased demand for AI native companies and enterprise adoption. There's an ongoing issue with heating problems after a mass change earlier this year, which the speaker addresses briefly. Investors want to know if the company can execute its roadmap and improve supply chain management for blackwell production. They also inquire about specific components causing supply constraints. The company confirms they are working hard on increasing blackwell production and expect strong demand due to the generative AI revolution. Engineering efforts with various CSPs are ongoing, and systems from different companies are being set up. The text discusses how a company has successfully integrated AI supercomputers into custom data centers worldwide. They have developed seven different chips for their systems and work with numerous partners such as TSMC, Amphenol, Vertiv, SK Heineck, Micron, Spill Amcor, KYEC, Foxconn, Quanta, Wewin, Gush, Dell, HP, Supermicro, Lenovo, and more. The company is in a good position to ramp up the production of their blackwell systems this quarter, with an impressive supply chain supporting them. The company follows an annual roadmap and aims to increase platform performance while reducing costs associated with training, inferencing, and AI. This approach allows them to generate higher revenues for their partners. They plan on continuing this strategy as they believe it is important. Regarding the trajectory of Blackwell's ramping in 2021, it seems that Blackwell will overtake Hopper in Q4 (April). Colette mentioned that blackwell will bring down gross margins to the low 70s as it ramps up in April. The company aims to increase these margins quickly, hoping to reach mid-70s soon after. Hopper demand will continue through next year, with more blackwell shipments planned for each subsequent quarter. There are two significant shifts happening in computing: moving from coding on CPUs to machine learning on GPUs and the widespread adoption of generative AI enabled by machine learning. A trillion dollars' worth of computing systems and data centers worldwide are being modernized for machine learning. In this text, the speaker discusses two trends in AI and data centers. Firstly, they mention that these systems will be creating a new type of capability called generative AI, which can be compared to generating electricity. Secondly, they talk about how many AI services are running 24-7, similar to an AI factory. The speaker also mentions the growth and modernization of this industry for several years. They then address a question from Alain Avizic regarding NVIDIA's gross margins in the back half of calendar 25 and whether there will be periods of digestion along hardware deployment cycles. It is possible that we could reach the mid-70s in the second half of next year, but this will depend on how well data centers are modernized. The world's data centers need to be updated for machine learning and generative AI as they were built for a time when applications were written by hand and run on CPUs. IT continues to grow about 20-30% per year, so over the next four years, it is expected that the world's data centers will require modernization of around two trillion dollars. Additionally, generative AI is creating new market segments with services like OpenAI, Runway, Harvey and Writers generating intelligence in various fields. AI native companies are becoming more common due to platform shifts creating new opportunities for businesses. These companies aim to modernize IT and computing, as well as create factories for the production of artificial intelligence. The speaker also mentions a conversation about gross margins in the low 70s and questions about revenue growth in specific sectors such as Blackwell and Hopper. The speaker talks about improving yields, product improvements throughout the year to reach mid-70s. They mention H-200 experiencing significant growth in orders and speed. Hopper will continue to be sold in Q4 across all configurations including China. There is a discussion on inference market, with hopes that AI will succeed when every company does inference for various departments within the company. The speaker discusses how they hope companies are constantly using AI 24/7, leading to the rise of thousands of AI native startups. They mention their favorite application, Notebook LM, and introduce a new era of AI called physical AI which understands the human language and can predict future outcomes for industrial use. The speaker also mentions Omniverse as an enabling tool for these AIs to learn in synthetic environments with physics feedback instead of human input. Inference is seen as difficult but exciting progress is being made. Inference is difficult due to high accuracy and low latency requirements. Applications have long context lengths and models are getting larger. NVIDIA's architecture allows quick innovation in every direction with a large installed base. The data center business saw strong demand, multiple cloud CFP design wins for large scale clusters, but the networking business was down 15% sequentially. The networking business has experienced tremendous growth year over year since acquiring Melanox. Focus has been on building work in data centers with a critical part being networking. Sales are expected to rise again soon as more systems will be using their existing networking and new ones incorporated into large systems. Sovereign AI demand is strong, especially for individual countries' models, which the company continues to support through its pipeline. The speaker discusses growth opportunities with regional clouds and AI factories, particularly in Europe and Asia Pacific regions. They also mention challenges in gaming supply for this quarter but expect improvement in the new year. Regarding the change in administration in the U.S., it is too early to tell about any potential impact on tariffs or China business. The speaker discusses how their company works with suppliers worldwide, supporting any new administration decisions while also complying with regulations and serving customers to the best of their abilities. They mention pre-training, reinforcement learning, and inference as important components within an AI ecosystem, highlighting that most compute is currently used for pre-training foundation models. As technology advances, they expect all three areas to continue scaling. The text discusses the rapid growth in foundation models for AI and how this will require more compute power to continue improving performance while reducing costs. This is driven by two trends: the shift from traditional data center infrastructure to machine learning, and the rise of generative AI as an industry with significant potential for economic impact. Artificial intelligence (AI) is transforming various industries and companies worldwide. Enterprises are adopting AI technology to improve workflows and employee performance. Investments in industrial robotics have increased due to advancements in physical AI, leading to the development of new training infrastructure for foundation models. The age of robotics is approaching as countries recognize the importance of national AI infrastructure. NVIDIA has expertise in delivering full stack and full infrastructure solutions for various AI opportunities. These include hyper scale clouds, enterprise private clouds, sovereign regional AI clouds, on-premises systems, industrial edge devices, and robotics applications.