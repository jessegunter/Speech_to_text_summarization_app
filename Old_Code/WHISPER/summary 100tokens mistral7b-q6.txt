This is a transcript from NVIDIA's third quarter earnings conference call in fiscal 2025. The speaker introduces the participants and reminds listeners that the content of the call belongs to NVIDIA. They also mention that forward-looking statements made during this call are subject to risks and uncertainties, and actual results may differ materially from those discussed. Finally, they remind attendees that a replay of the webcast will be available until the next conference In Q3, NVIDIA reported record revenues of $35.1 billion, a 94% increase year-on-year and above the outlook of $32.5 billion. All market platforms experienced strong sequential and yearly growth driven by adoption of NVIDIA's accelerated computing and AI technologies. Data center revenue reached $30.8 billion, up 17% sequentially and 112% year-on-year due NVIDIA is a leading inference platform with a large install base and rich software ecosystem that encourages developers to optimize for it. The company has made rapid advancements in its algorithms, boosting Hopper inference throughput by 5x in one year and reducing time to first token by 5x. An upcoming release of NVIDIA's NEM is expected to further improve performance by an additional 2.4x. Blackwell, a full stack AI data center Blackwell has made its debut on the ML Perf training results and achieved impressive performance gains over high-end GPUs. The technology is cost-effective, with only 64 Blackwell GPUs required for GTT-3 benchmark compared to 256 H100s, resulting in a 4X reduction in cost. NVIDIA's new architecture enables up to 30x faster inference performance and improved scaling throughput and response time. The rise Over 900 companies use NVIDIA technology for their AI and robotics needs. The company expects its annual revenue to double this year due to a growing pipeline of customers. Industrial manufacturers like Foxconn are using NVIDIA's Omiverse platform to improve efficiency in their factories. In China, data center revenue is increasing but remains competitive. Lastly, sovereign AI initiatives by countries such as India are gaining momentum with the adoption of NVIDIA accelerated computing technology for a Infosys, TLC, Wipro are adopting NVIDIA AI Enterprise to train nearly half a million developers and consultants in building and running AI agents. In Japan, SoftBank is constructing the nation's most powerful AI supercomputer with NVIDIA DGX Blackwell and Kartsman Finnebaum. They are also partnering with NVIDIA to transform telecommunications networks into distributed AI networks using AI Arial and AI RAN platforms Nvidia's RTX GPUs experienced strong back-to-school sales, with healthy channel inventory preparing for the holiday season. The company began shipping new GeForce RTX AI PCs from ASUS and MSI, which utilize Microsoft's co-pilot plus capabilities in Q4. These machines are designed to supercharge gaming, photo and video editing, image generation, and coding through the use of RTX ray tracing and AI technologies. Nvidia celebrated its The company returned $11.2 billion to shareholders through dividends and buybacks during Q3. For Q4, total revenue is expected to be around $37.5 billion with a 2% variance due to high demand for hopper architecture and Blackwell products. Gaming revenues are predicted to decline sequentially in Q4 due to supply constraints. The company's focus on ramping up Blackwell production is expected to moderate margins to the low 70 The company will be attending several conferences and hosting a Q&A session for financial analysts. They are discussing large language models and their scalability issues. They mention that there are three ways to scale these models - pre-training, post-training, and inference time scaling (test time scaling). The text discusses the advancements in AI models and their scaling techniques. It mentions that as foundation models improve, demand for infrastructure increases. The company has a large install base of inference platforms which will continue to grow with new models like black wolves. Enterprise adoption of agentic AI is also increasing, leading to more demand from various sources. The company has been working hard on increasing the production of Blackwell chips and will deliver more than previously estimated this quarter. Demand for Blackwell exceeds supply due to the beginning of a generative AI revolution. Execution is going well, and there are many engineering efforts worldwide. Supply chain teams are collaborating with partners to increase production through next year. The speaker discusses the process of integrating AI supercomputers into custom data centers worldwide and highlights their expertise in doing so. They mention that they have shipped zero units of Blackwell last quarter but are planning to ramp up production this quarter. The company has a strong supply chain, with partnerships from various companies such as TSMC, Amphenol, Vertiv, SK Heineck, Micron, and more. Despite the challenges in scaling production, they believe they are on The company has an annual roadmap and plans to continue executing on it to increase platform performance. This also reduces costs for training, inferencing, and AI, making it more accessible. Data centers have a fixed size with limited power, so the best performance per watt generates the highest revenues for customers. The annual rhythm is important for reducing cost and increasing revenue. Blackwell's trajectory will ramp up this year, possibly exceeding previous expectations of several billions in January. It The speaker discusses Blackwell, which will initially have low gross margins in the 70% range as it ramps up production. However, these margins are expected to improve quickly, reaching mid-70s levels soon after. Demand for hoppers is also projected to continue into next year. This period marks a significant shift in computing from coding on CPUs to machine learning on GPUs, with all companies now focusing on machine learning and generative AI. The modernization AI is being referred to as a new type of capability that will be generated by data centers, similar to how electricity is produced. These generators are expected to run 24/7 and serve a large number of customers. The speaker believes this growth and modernization will continue for several years. They also discuss the idea of hardware deployment cycles having periods of digestion along the way but find it too premature to predict when that phase would occur or how many quarters of shipments are needed for It is possible that we could reach the mid-70s in the second half of next year, but it depends on how well the mix of ramp goes. The world's data centers need to be modernized for machine learning and generative AI, which will require trillions of dollars over the next few years. Additionally, new market segments are emerging with companies like OpenAI creating brand-new services that were not available before, such as digital artist intelligence or legal intelligence. AI native companies are emerging due to platform shifts and new opportunities for innovation. These companies aim to modernize IT and computing, while also creating AI factories for the production of artificial intelligence. In response to a question about gross margins and revenue growth, it is mentioned that they could be in the low 70s range or higher, depending on various factors such as supply constraints and market conditions. The speaker discusses improvements in yields, growth in H-200 orders, and the possibility of Hopper growing between Q3 and Q4. They also mention the inference market and their hopes for a future where AI is used extensively within companies for various tasks. The speaker discusses the growing use of AI-based applications and startups, with a focus on physical AI which understands human language as well as the physical world. They mention Omniverse, a platform designed to enable AIs to learn in a virtual environment using synthetic data and physics feedback instead of human input. Inference is seen as challenging but exciting for future growth in this field. Inference is difficult because it requires high accuracy, throughput and low latency. Applications have long context lengths, making models larger and more complex. NVIDIA's architecture allows for quick innovation due to its strong ecosystem. The data center business has seen a 15% decrease in networking but strong demand with multiple cloud design wins for large scale clusters. The networking business has experienced tremendous growth year over year since acquiring Melanox. Focusing on data centers, the company's ability to sell its networking products alongside systems is growing well. There will be more systems incorporating their existing networking and new ones in the future. Sovereign AI demand remains strong with a pipeline intact for building foundational models in various countries. Supply constraints may exist in gaming due to shifting focus towards data centers, but overall growth continues. The speaker discusses growth opportunities with regional clouds and AI factories, focusing on Europe and Asia Pacific regions. They also mention challenges in gaming supply for this quarter but expect improvement in the new year. Regarding sequential growth, they emphasize taking it one quarter at a time and building what is needed to ship in terms of Blackwell. Lastly, they address concerns about tariffs and changes in administration with regard to their China business, stating that it's too early for any definitive The speaker discusses their company's approach to working with suppliers, supporting new administrations, complying with regulations, and competing in the marketplace. They mention pre-training, reinforcement learning, and inference as important components of an AI ecosystem and note that currently, a large portion of compute is used for pre-training foundation models. The speaker believes it's sensible that all three areas are scaling based on their company's focus. The development of multi-modality foundation models requires more compute power due to the increasing amount of video data being used for training. This will lead to continuous scaling in pre-training, post-training, and inference times. As AI adoption grows globally, NVIDIA's business is benefiting from a platform shift towards machine learning and the rise of generative AI as an industry. The demand for Hopper and anticipation for Blackwell are high due to factors such as more foundation Artificial intelligence (AI) is transforming various industries, companies, and countries as enterprises adopt agentic AI to improve workflows. Investments in industrial robotics are increasing due to advancements in physical AI. Researchers are training foundation models on large amounts of data, leading to the rise of robots. Countries worldwide recognize these trends and are developing their national AI infrastructure. NVIDIA is well-positioned to serve the vast opportunities in AI and robotics across various platforms