This is a transcript from NVIDIA's third quarter earnings conference call in fiscal 2025. The speaker welcomes everyone and introduces the speakers, Jensen Wong (CEO) and Collette Cress (C In Q3, NVIDIA achieved record revenues of $35.1 billion, a 94% increase year-on-year and above the outlook of $32.5 billion. All market platforms experienced strong sequential NVIDIA is a leading inference platform with a large install base and rich software ecosystem that encourages developers to optimize for it. The company has made rapid advancements in its algorithms, boosting hopper inference throughput by 5 Blackwell has made its debut on the ML Perf training results and demonstrated an impressive leap in performance over high-end systems. This advancement is expected to reduce compute costs significantly. The NVIDIA Blackwell architecture, along with new AI native Over 900 companies use NVIDIA NEM and its adoption is increasing rapidly. The company expects a significant increase in revenue from AI Enterprise this year. Their software, service, and support revenues are expected to annualize at over $ Infosys, TLC, Wipro are adopting NVIDIA AI Enterprise to train half a million developers and consultants in building and running AI agents. In Japan, SoftBank is partnering with NVIDIA for the most Nvidia's GeForce RTX GPUs have seen strong sales during back-to-school season, with healthy channel inventory preparing for the holiday season. The company has begun shipping AI PCs from ASUS and MSI, using Microsoft The company returned $11.2 billion to shareholders through dividends and buybacks during Q3. It anticipates total revenue of $37.5 billion in Q4 with a 2% variance due to high demand for hopper We will be attending several conferences including UBS Global Technology and AI conference on December 3rd and CES in Las Vegas where Genson will deliver a keynote on January 6th. A Q&A session for financial analysts The text discusses how AI models are improving in quality as they think longer and consider various techniques. It mentions three ways of scaling and the increasing demand for infrastructure due to these advancements. The company is also seeing a growth in inference time An investor asked if the company can execute its roadmap for Ultra next year and the transition to Ruben in 26. The speaker said Blackwell production is increasing more than previously estimated this quarter due to supply chain efforts. Demand The text discusses how a company has built an AI supercomputer and integrated it into custom data centers worldwide. They have done several generations of integration and are very good at it but still require significant engineering work. There is now a plan to shift The company follows an annual roadmap which aims at increasing platform performance and reducing costs associated with training, inferencing, and AI. This approach benefits customers by generating higher revenues for them. In addition, focusing on power efficiency allows the company to maxim The speaker discusses Blackwell ramping up in April, which will cause gross margins to be in the low 70s at first but improve quickly after that. They mention how there are two significant shifts happening in computing - moving from coding AI is becoming a new type of capability that will be generated by data centers, similar to how electricity is produced. These generators will run 24/7 and serve as an "AI factory." The growth and modernization of this industry are It is possible that we could reach the mid-70s in the second half of next year, but it depends on how well data centers are modernized. Data centers need to be updated for machine learning and generative AI as IT continues to AI native companies are becoming more common due to platform shifts and new opportunities. These companies aim to modernize IT and computing, while also creating AI factories for the production of artificial intelligence. In response to a question about gross margins and revenue growth The speaker discusses improvements in yields, with a goal to reach mid-70s by the end of the year. They mention the growth of H-200, which is their fastest growing product. Hopper will continue to be sold The speaker discusses how they hope companies are doing inference 24/7, leading to the creation of thousands of AI native startups. They mention their favorite application, Notebook LM, and introduce a new genre of AI called physical Inference is difficult due to high accuracy and low latency requirements while maintaining cost-effectiveness. Applications with long context lengths are growing larger and more complex, making it harder to build computers capable of inference. NVIDIA's architecture The networking business has experienced tremendous growth year over year since acquiring Melanox. The focus has been on building work in data centers with a critical part being networking. The company's ability to sell its networking products along with many systems is continuing The speaker discusses growth opportunities in regional clouds and AI factories, particularly in Europe and Asia Pacific regions. They also mention challenges with gaming supply for this quarter but expect improvement in the new year. Regarding the change in administration in the U. The speaker discusses how their company works with suppliers worldwide, supporting any new administration decisions while also complying with regulations and competing in the marketplace. They mention the importance of pre-training, reinforcement learning, and inference within an AI ecosystem The speaker discusses the growth in foundation models for AI and how they are trained on large amounts of video data. This will require more compute power to scale pre-training, post-training, and inference times. As AI adoption grows globally Artificial intelligence (AI) is transforming various industries and companies worldwide. Enterprises are adopting AI technology to improve workflows, making employees more efficient in their jobs. Investments in industrial robotics have increased due to advancements in