This is a transcript from NVIDIA's third quarter earnings conference call in fiscal 2025. The speakers are Jensen Wong, president and CEO, and Collette Cress, executive vice president and CFO. They remind listeners that the content of the call belongs to NVIDIA and cannot be reproduced or transcribed without their consent. Forward-looking statements made during this call may differ from actual results due to various risks and uncertainties. The discussion will include non-GAAP financial measures, and a replay of the webcast will be available until the conference call for the fourth quarter of fiscal 2025. The company had a record quarter with 17% sequential and 94% year-on-year revenue growth, reaching $35.1 billion. All market platforms experienced strong growth driven by the adoption of NVIDIA's accelerated computing and AI technology. Data center revenue reached $30.8 billion, up 17% sequentially and 112% year-on-year due to exceptional demand for NVIDIA Hopper products. Cloud service providers accounted for half of data center sales with revenue increasing more than two times year-on-year. Consumer internet revenue doubled as companies scaled their NVIDIA Hopper infrastructure to support next generation AI models and applications. NVIDIA is a leading inference platform with a large install base and rich software ecosystem that encourages developers to optimize for it. Rapid advancements in their algorithms have improved hopper inference throughput by 5x in one year and reduced time to first token by 5x. Their upcoming release, NVIDIA NEM, will further boost performance by an additional 2.4x. Continuous performance optimization is a key feature of NVIDIA's products, which drive economic returns for their customers. Blackwell has entered full production after a successful mouse change and shipped 13,000 GPU samples to customers in the third quarter. It is a full stack AI data center scale system with customizable Blackwell made its debut on the ML Perf training results and delivered impressive performance improvements over high-end GPUs. The new architecture enables up to 30X faster inference performance and is ideal for running AI reasoning applications. Many startups are already using AI services, with major companies like Google, Meta, Microsoft, and OpenAI leading the way. Enterprise AI is growing rapidly, with industry leaders working on co-pilots and agents using NVIDIA's technology. Consulting firms such as Accenture and Deloitte are also adopting NVIDIA AI for their clients. Over 900 companies use NVIDIA's technology, with rapid growth seen in its AI Enterprise monetization. The company expects full-year revenue to double from last year and is building a strong pipeline. Software, service, and support revenues are expected to annualize at $2 billion by the end of this year. Industrial AI and robotics are accelerating due to breakthroughs in physical AI models like NVIDIA NEMO for enterprise agents and Omiverse for developers. Large manufacturers such as Foxconn are adopting these tools to improve efficiency. In China, data center revenue has grown sequentially but remains below pre-export control levels. The company will continue to comply with export controls while serving customers. Last NVIDIA is partnering with companies like Infosys, TLC, Wipro, SoftBank, Fujitsu, NEC, and NTT to adopt AI technology in various industries. These partnerships aim at upskilling developers and consultants to build and run AI agents on the platform. In Japan, SoftBank is building an AI supercomputer with NVIDIA DGX Blackwell and Kartsman Finnebaum. The company also plans to transform telecommunications networks into a distributed AI network in collaboration with NVIDIA AI Arial and AI RAN platforms. Networking revenue has increased by 20% year on year, driven by InfiniBand and Ethernet switches Nvidia's RTX sales have been strong thanks to back-to-school purchases and the company is preparing for the holiday season. New GeForce RTX AI PCs are being shipped by ASUS and MSI with Microsoft's co-pilot capabilities expected in Q4. These machines use ray tracing and AI technologies to improve gaming, photo editing, image generation, and coding. The 25th anniversary of the world's first GPU was celebrated this past quarter. ProViz revenue increased by 7% sequentially and 17% year on year due to Nvidia RTX workstations being preferred for professional graphics tasks. AI is becoming a significant demand driver in automotive, with revenue The company returned $11.2 billion to shareholders through dividends and stock buybacks during Q3. For Q4, total revenue is expected to be around $37.5 billion with a 2% variance due to increased demand for hopper architecture and Blackwell products. However, gaming revenue may decline sequentially due to supply constraints. The company's focus on ramping up Blackwell product sales will lead to moderated margins in the low 70s when fully ramped, eventually reaching mid-70s margins. Gap and non-gap operating expenses are estimated at $4.8 billion and $3.4 billion respectively. Other income and expenses are expected to be around a gain The company will be attending various conferences including UBS Global Technology and AI conference on December 3rd and CES in Las Vegas where Genson will deliver a keynote on January 6th. They will also host a Q&A session for financial analysts on January 7th. An earnings call is scheduled for February 26th, 2025. The discussion revolves around the debate over whether scaling large language models has been solved and how the company is helping customers work through these issues. It mentions that pre-training scaling continues to be a factor but there are two other ways of scaling: post-training scaling using reinforcement learning AI feedback, synthetic data generated data, and inference time scaling The text discusses how a thinking process works similarly to human thought and mentions three ways of scaling in the industry. It highlights that demand is high due to pre-training, scaling, post-training, and inference time scaling. Additionally, it talks about being the largest inference platform globally with an extensive install base and growing AI native companies. The text also touches on enterprise adoption of agentic AI and mentions a recent mass change execution that faced heating issues reports over the weekend. An investor asked about the company's ability to execute on its roadmap and their progress in addressing supply constraints. The speaker responded by stating that Blackwell production is increasing more than previously estimated, thanks to the efforts of the supply chain team working with partners. They acknowledged that demand currently exceeds supply due to the beginning stages of a generative AI revolution. Engineering work is being done across the world, and various companies are racing to be first in implementing these systems. The AI supercomputer is integrated into custom data centers worldwide and has a complex supply chain involving many companies such as TSMC, Amphenol, Vertiv, SK Heineck, Micron, Spill Amcor, KYEC, Foxconn, Quanta, Wewin, Gush, Dell, HP, Supermicro, Lenovo. The company is in great shape with the blackwell ramp and has executed its roadmap well. The company follows an annual roadmap and aims to increase platform performance while reducing costs related to training, inferencing, and AI. They focus on maximizing revenues for their partners by offering high-performance per watt. The trajectory of Blackwell's ramp is expected to be significant this year, with recent months showing promising results that exceed initial expectations. It is anticipated that Blackwell will surpass Hopper in the April quarter. The speaker discusses Blackwell, which has caused gross margins to drop into the low 70s as it ramps up. They mention that this pressure on gross margin will be at its worst in April but will improve over time. As more blackwells are shipped and demand continues through next year, they expect gross margins to rise quickly to the mid-70s. The speaker also highlights two significant shifts happening in computing: moving from coding running on CPUs to machine learning running on GPUs, which is now widespread; and modernizing data centers for machine learning. In this text, the speaker discusses how data centers are becoming AI factories that generate artificial intelligence (AI) like electricity is generated. They mention that many AI services already run 24/7 and expect this growth to continue for several years. The speaker also talks about NVIDIA's gross margins and whether they will recover to the mid-70s in the back half of calendar 25, as well as addressing the concept of hardware deployment cycles with periods of digestion along the way. They are asked how many quarters of shipments are needed for this first phase and if it can continue into calendar 26. It is possible that we could reach the mid-70s in the second half of next year, but it depends on how well data centers are modernized. Data centers need to be updated for machine learning and generative AI, which will grow significantly over the next few years. Generative AI is a new market segment with companies like OpenAI creating intelligence through their services. AI native companies are emerging due to platform shifts and new opportunities. These companies aim to modernize IT and computing, while also creating AI factories for the production of artificial intelligence. The speaker mentions guidance on total revenues in the next quarter but does not provide specific numbers. They discuss Blackwell's ramp and its comparison with Hopper, mentioning supply constraints and China's performance as factors affecting their results. The speaker discusses improving yields, product growth, and sales of Hopper in Q4. They mention that H-200 has seen significant growth and will continue to be sold during this period. There is also a discussion about the inference market and how AI's success depends on companies doing inference within their organizations for various departments. The speaker discusses the increasing use of AI in various applications and the rise of physical AI, which understands human language as well as the physical world. They mention Omniverse, a platform designed to enable AIs to learn through synthetic data generation and reinforcement learning with physics feedback. Inference is challenging but exciting developments are happening in this field. Inference is difficult because it requires high accuracy, throughput and low latency while dealing with long context lengths and larger models. NVIDIA's architecture allows for quick innovation due to its fantastic ecosystem. The company has a large installed base that enables deployment of new technologies worldwide. Networking business saw a 15% decrease in the last quarter but strong demand is expected, with multiple cloud design wins for large scale clusters. The networking business has experienced tremendous growth year over year since acquiring Melanox. The focus has been on building work in data centers with networking being a critical part of it. There is an expectation for growth to continue, especially as more systems are integrated into large systems provided by the company. Sovereign AI demand remains strong and continues to grow globally, with the pipeline still intact despite challenges faced during the denitivate AI era. The speaker discusses growth opportunities for regional clouds and AI factories, particularly in Europe and Asia Pacific regions. They also mention challenges with gaming supply ramping up quickly and their expectations for future sequential growth. Lastly, they address concerns about the change in administration in the U.S. and potential tariffs or changes affecting their China business, stating that it's too early to predict any specific outcomes. The speaker discusses how their company works with suppliers worldwide, supporting the new administration while complying with regulations and competing in the marketplace. They mention pre-training, reinforcement learning, and inference as important components of an AI ecosystem, but emphasize that most compute resources currently go into pre-training foundation models due to recent technological advancements. The growth in foundation models for AI requires more compute power to train and process them efficiently. This is driven by two trends: the shift from traditional data center infrastructure to software 2.0 using machine learning, and the rise of generative AI as an industry. As a result, there are now more foundation model makers, increased computing scale for pre-training and post-training, and a growing number of AI native startups and inference services. The introduction of ChatGPT has also led to the emergence of test time scaling, which consumes even more compute resources. Artificial intelligence (AI) is transforming various industries and companies worldwide. Enterprises are adopting agentic AI to improve workflows and make employees more efficient. Investments in industrial robotics have increased due to advancements in physical AI technology. Researchers are training foundation models on large amounts of data, leading to the rise of robots. Countries around the world are recognizing these trends and focusing on developing their national AI infrastructure. NVIDIA is well-positioned to serve the growing AI and robotics markets with its expertise, scale, and ability to deliver full stack and full infrastructure solutions across various platforms.