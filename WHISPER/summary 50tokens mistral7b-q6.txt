This is a transcript from NVIDIA's third quarter earnings conference call in fiscal 2025. The speaker introduces the participants and reminds listeners that the content of the call belongs to NVIDIA. They also mention forward- In Q3, NVIDIA reported record revenues of $35.1 billion, a 94% increase year-on-year and above the outlook of $32.5 billion. All market platforms experienced strong sequential NVIDIA is a leading inference platform with an extensive install base and software ecosystem that encourages developers to optimize for it. The company has made significant advancements in its algorithms, boosting Hopper inference throughput by 5x Blackwell has made its debut on the ML Perf training results and achieved impressive performance improvements over high-end GPUs. The technology allows for reduced compute costs with just 64 Blackwell GPUs required compared to 256 H1 Over 900 companies use NVIDIA's technology, and its adoption is accelerating rapidly. The company expects AI Enterprise full-year revenue to double from last year. Software, service, and support revenues are on track to hit NVIDIA is partnering with companies like Infosys, TLC, Wipro, SoftBank, Fujitsu, NEC, and NTT to adopt AI technology in various industries. They are also launching new products such Nvidia's RTX GPUs have seen strong sales during the back-to-school season, with consumers choosing them for gaming, creative, and AI applications. Channel inventory remains healthy as they prepare for the holiday season. New GeForce The company returned $11.2 billion to shareholders through dividends and buybacks during Q3. For Q4, total revenue is expected to be around $37.5 billion with a 2% variance due to increased demand for The company will be attending several conferences and events including a keynote at CES on January 6th and a Q&A session for financial analysts on January 7th. They will also host an earnings call to discuss results from The text discusses how a system thinks and produces high-quality answers by considering various techniques such as chain of thoughts and multi-path planning. It mentions that there are three ways of scaling, which has led to increased demand for infrastructure. The The company is working on executing its roadmap and has been able to deliver more Blackwells than previously estimated this quarter. Demand for their product exceeds supply due to the beginning of a generative AI revolution. Engineering efforts are being made The AI supercomputer is integrated into custom data centers worldwide, and there are seven different chips required for the Blackwell systems. The supply chain necessary to scale production has been incredible, with many companies involved in the process. Despite shipping zero units last The company follows an annual roadmap and plans to continue executing on this plan to increase platform performance. This not only reduces costs but also makes AI more accessible. Data centers have a fixed size, so focusing on power efficiency is crucial for generating the The speaker discusses Blackwell ramping up gross margins to the low 70s in April, with an expectation that they will increase to mid-70s quickly after. They mention that hopper demand will continue through next year and AI factories are being created as data centers to generate artificial intelligence (AI) similar to how electricity is generated. These new systems will be running 24/7 and catering to a large number of customers, making them unlike traditional data centers It is possible that we could reach the mid-70s in the second half of next year, but it depends on how well data centers are modernized. Over the next few years, the world's data centers will need to be updated AI native companies are emerging due to platform shifts and new opportunities. These companies aim to modernize IT and computing, as well as create AI factories for the production of artificial intelligence. The speaker also discusses their company's gross margins and The speaker discusses improvements in yields, product development, and sales expectations for H-200, a fast-growing product. Hopper will continue to be sold in Q4 across different configurations. Inference market growth is expected as AI The speaker discusses the growing use of AI native startups and applications like Google Notebook LM, which generate tokens through inference processes. They mention a new era of AI called physical AI, which understands human language as well as the physical world Inference is difficult because it requires high accuracy, throughput and low latency. Applications have long context lengths and models are getting larger with multi-modality. NVIDIA's architecture allows quick innovation due to its fantastic ecosystem. The The networking business has experienced tremendous growth year over year since acquiring Melanox. The focus has been on building work in data centers with networking being a critical part of it. The company's ability to sell its networking products along with their systems The speaker discusses growth opportunities for regional clouds and AI factories, particularly in Europe and Asia Pacific regions. They also mention challenges with gaming supply ramping up quickly but expect improvements in the new calendar year. Regarding sequential growth, they emphas The speaker discusses their company's collaboration with suppliers, support for new administrations, compliance with regulations, and competition in the marketplace. They mention pre-training, reinforcement learning, and inference as important components of an AI ecosystem, The growth in foundation models for AI requires more compute power to handle large amounts of video data and scale pre-training, post-training, and inference times. This will drive the need for increased performance at lower costs to continue advancing the AI Artificial intelligence (AI) is transforming various industries, companies, and countries as enterprises adopt agentic AI to improve workflows. Investments in industrial robotics are increasing due to advancements in physical AI. Researchers are training foundation